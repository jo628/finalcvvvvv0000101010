"""Waste Classification GUIAuthor: Zeyad-Diaa-1242Updated: 2025-05-07 06:00:26"""import osimport cv2import numpy as npimport tensorflow as tffrom PIL import Imageimport matplotlib.pyplot as pltfrom flask import Flask, render_template, request, jsonify, send_from_directoryfrom werkzeug.utils import secure_filenameimport base64from datetime import datetimeimport threadingimport webbrowserimport timeimport pickleimport sysimport json# ConfigurationDEBUG = TrueSAVE_DEBUG_IMAGES = TrueDEBUG_DIR = "debug_output"CLASSES = ['Boxes', 'Metal', 'Plastic']  # Keep original 3 classes as specifiedCONFIDENCE_THRESHOLD = 0.9  # Higher threshold for more reliable predictions# Setup debug directoryif SAVE_DEBUG_IMAGES and not os.path.exists(DEBUG_DIR):    os.makedirs(DEBUG_DIR)def debug_print(*args, **kwargs):    """Print debug information with timestamps"""    if DEBUG:        timestamp = datetime.now().strftime('[%H:%M:%S]')        print(timestamp, *args, **kwargs)        sys.stdout.flush()# Initialize Flask appapp = Flask(__name__)app.config['UPLOAD_FOLDER'] = 'uploads'app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg'}# Create upload folder if it doesn't existos.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)# Load models and supporting filesMODEL_PATH = 'waste_classifier_model.h5'if os.path.exists('./model_checkpoints/waste_model_best.h5'):    MODEL_PATH = './model_checkpoints/waste_model_best.h5'    debug_print(f"Using best model: {MODEL_PATH}")else:    debug_print(f"Using fallback model: {MODEL_PATH}")FEATURE_CONFIG_PATH = './exported_models/feature_config.pkl'FEATURE_SCALER_PATH = './exported_models/feature_scaler.pkl'FEATURE_MODEL_PATH = './exported_models/feature_extractor_base_model.h5'# Load classification model with validationdebug_print(f"Loading classification model from {MODEL_PATH}")try:    model = tf.keras.models.load_model(MODEL_PATH)    debug_print("Classification model loaded successfully")    debug_print(f"Model output shape: {model.output_shape}")    debug_print(f"Model input shape: {model.input_shape}")        # Validate model output matches class count    expected_output_size = len(CLASSES)    actual_output_size = model.output_shape[1]        if actual_output_size != expected_output_size:        debug_print(f"WARNING: Model output size ({actual_output_size}) doesn't match expected class count ({expected_output_size})")        debug_print(f"This may cause incorrect classifications")except Exception as e:    debug_print(f"Error loading classification model: {e}")    raise# Load feature configuration if availablefeature_config = Noneif os.path.exists(FEATURE_CONFIG_PATH):    try:        with open(FEATURE_CONFIG_PATH, 'rb') as f:            feature_config = pickle.load(f)        debug_print(f"Loaded feature configuration from {FEATURE_CONFIG_PATH}")    except Exception as e:        debug_print(f"Error loading feature configuration: {e}")# Load feature scaler if availablefeature_scaler = Noneif os.path.exists(FEATURE_SCALER_PATH):    try:        with open(FEATURE_SCALER_PATH, 'rb') as f:            feature_scaler = pickle.load(f)        debug_print(f"Loaded feature scaler from {FEATURE_SCALER_PATH}")    except Exception as e:        debug_print(f"Error loading feature scaler: {e}")# Load feature base model if availablefeature_base_model = Noneif os.path.exists(FEATURE_MODEL_PATH):    try:        feature_base_model = tf.keras.models.load_model(FEATURE_MODEL_PATH)        debug_print(f"Loaded feature extractor base model from {FEATURE_MODEL_PATH}")    except Exception as e:        debug_print(f"Error loading feature extractor base model: {e}")# Initialize feature extractorfrom feature_extraction import FeatureExtractorfeature_extractor = FeatureExtractor(input_shape=(224, 224, 3))debug_print("Initialized feature extractor")def allowed_file(filename):    """Check if file has an allowed extension"""    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']def preprocess_image(file_path):    """Load and preprocess an image from a file path"""    img = cv2.imread(file_path)    if img is None:        raise ValueError(f"Could not read image from {file_path}")    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    return imgdef object_detection(img):    """Generate candidate regions for classification"""    height, width = img.shape[:2]    boxes = []        # Always include the full image    boxes.append((0, 0, width, height))        # Add centered regions of different sizes    for scale in [0.8, 0.6, 0.4]:        new_w = int(width * scale)        new_h = int(height * scale)        x = (width - new_w) // 2        y = (height - new_h) // 2        boxes.append((x, y, new_w, new_h))        # Add quarters of the image    w_half, h_half = width // 2, height // 2    boxes.extend([        (0, 0, w_half, h_half),              # Top-left        (w_half, 0, w_half, h_half),         # Top-right        (0, h_half, w_half, h_half),         # Bottom-left        (w_half, h_half, w_half, h_half),    # Bottom-right    ])        # Add grid-based regions    for grid_size in [2, 3]:        cell_w = width // grid_size        cell_h = height // grid_size                for r in range(grid_size):            for c in range(grid_size):                x = c * cell_w                y = r * cell_h                boxes.append((x, y, cell_w, cell_h))        # Add some overlapping regions to improve detection    overlap_scales = [0.7, 0.5]    for scale in overlap_scales:        w_scaled = int(width * scale)        h_scaled = int(height * scale)                x_offsets = [0, (width - w_scaled)]        y_offsets = [0, (height - h_scaled)]                for x in x_offsets:            for y in y_offsets:                boxes.append((x, y, w_scaled, h_scaled))        debug_print(f"Generated {len(boxes)} candidate regions")    return boxesdef extract_and_classify(img, return_all_scores=False):    """Extract features and classify an image"""    # Resize consistently     img_resized = cv2.resize(img, (224, 224))        # Save debug image if enabled    if SAVE_DEBUG_IMAGES:        debug_timestamp = datetime.now().strftime('%Y%m%d%H%M%S')        debug_img_path = os.path.join(DEBUG_DIR, f"debug_resized_{debug_timestamp}.jpg")        cv2.imwrite(debug_img_path, cv2.cvtColor(img_resized, cv2.COLOR_RGB2BGR))        # Extract features    try:        features = feature_extractor.extract_features(img_resized)                # Save feature debug info        if SAVE_DEBUG_IMAGES:            debug_features_path = os.path.join(DEBUG_DIR, f"debug_features_{debug_timestamp}.txt")            with open(debug_features_path, 'w') as f:                f.write(f"Shape: {features.shape}\n")                f.write(f"Mean: {np.mean(features)}\n")                f.write(f"Std: {np.std(features)}\n")                f.write(f"Min: {np.min(features)}\n")                f.write(f"Max: {np.max(features)}\n")                f.write(f"NaN count: {np.isnan(features).sum()}\n")                f.write(f"Inf count: {np.isinf(features).sum()}\n")                f.write("\nFirst 20 values:\n")                f.write(str(features[:20]))                # Handle NaN and Inf values        features = np.nan_to_num(features)                # Apply scaling if feature scaler is available        if feature_scaler is not None:            if features.ndim == 1:                features = feature_scaler.transform(features.reshape(1, -1)).flatten()            else:                features = feature_scaler.transform(features)                        # Save scaled feature debug info            if SAVE_DEBUG_IMAGES:                debug_scaled_path = os.path.join(DEBUG_DIR, f"debug_scaled_{debug_timestamp}.txt")                with open(debug_scaled_path, 'w') as f:                    f.write(f"Shape after scaling: {features.shape}\n")                    f.write(f"Mean: {np.mean(features)}\n")                    f.write(f"Std: {np.std(features)}\n")                    f.write(f"Min: {np.min(features)}\n")                    f.write(f"Max: {np.max(features)}\n")                    f.write("\nFirst 20 values after scaling:\n")                    f.write(str(features[:20]))                # Ensure feature dimension matches model input        expected_input_dim = model.input_shape[1]        actual_feature_dim = features.shape[0]                if expected_input_dim != actual_feature_dim:            debug_print(f"WARNING: Feature dimension ({actual_feature_dim}) does not match model input dimension ({expected_input_dim})")                        # If features are larger than expected, truncate            if actual_feature_dim > expected_input_dim:                features = features[:expected_input_dim]                debug_print(f"Truncated features to match model input dimension")            # If features are smaller, pad with zeros            else:                pad_width = expected_input_dim - actual_feature_dim                features = np.pad(features, (0, pad_width), mode='constant')                debug_print(f"Padded features with {pad_width} zeros to match model input dimension")                # Add batch dimension for model input        features = np.expand_dims(features, axis=0)                # Make prediction        predictions = model.predict(features, verbose=0)[0]                # Save prediction debug info        if SAVE_DEBUG_IMAGES:            debug_preds_path = os.path.join(DEBUG_DIR, f"debug_predictions_{debug_timestamp}.json")            with open(debug_preds_path, 'w') as f:                preds_dict = {cls: float(score) for cls, score in zip(CLASSES, predictions[:len(CLASSES)])}                json.dump(preds_dict, f, indent=2)                # Ensure predictions match the number of classes        if len(predictions) >= len(CLASSES):            class_predictions = predictions[:len(CLASSES)]        else:            class_predictions = np.pad(predictions, (0, len(CLASSES) - len(predictions)))                # Get class index and confidence        class_idx = np.argmax(class_predictions)        confidence = class_predictions[class_idx]                # Map to class name        class_name = CLASSES[class_idx]                if return_all_scores:            return class_name, confidence, class_predictions        return class_name, confidence            except Exception as e:        debug_print(f"Error in extract_and_classify: {e}")        import traceback        debug_print(traceback.format_exc())                if return_all_scores:            return "Unknown", 0.0, np.zeros(len(CLASSES))        return "Unknown", 0.0def classify_regions(img, boxes):    """Classify all candidate regions and return results"""    debug_print(f"Starting classification of {len(boxes)} regions")    results = []        for i, box in enumerate(boxes):        x, y, w, h = box                # Ensure box is within image bounds        x = max(0, x)        y = max(0, y)        w = min(w, img.shape[1] - x)        h = min(h, img.shape[0] - y)                # Skip very small regions        if w < 20 or h < 20:            continue                region = img[y:y+h, x:x+w]                # Save region for debugging        if SAVE_DEBUG_IMAGES:            debug_timestamp = datetime.now().strftime('%Y%m%d%H%M%S')            region_path = os.path.join(DEBUG_DIR, f"region_{i}_{debug_timestamp}.jpg")            cv2.imwrite(region_path, cv2.cvtColor(region, cv2.COLOR_RGB2BGR))                try:            class_name, confidence, all_scores = extract_and_classify(region, return_all_scores=True)                        debug_print(f"  Box {i}: class={class_name}, conf={confidence:.4f}")            debug_print(f"  All scores: {dict(zip(CLASSES, all_scores))}")                        # Only add high-confidence predictions            if confidence > CONFIDENCE_THRESHOLD:                results.append({                    'box': box,                    'class': class_name,                    'confidence': float(confidence),                    'all_scores': {cls: float(score) for cls, score in zip(CLASSES, all_scores)}                })        except Exception as e:            debug_print(f"  Error classifying box {i}: {e}")        # If no regions were confidently classified, use whole image    if not results:        debug_print("No high-confidence regions, using whole image")        try:            class_name, confidence, all_scores = extract_and_classify(img, return_all_scores=True)            h, w = img.shape[:2]            center_box = (w//4, h//4, w//2, h//2)                        results.append({                'box': center_box,                'class': class_name,                'confidence': float(confidence),                'all_scores': {cls: float(score) for cls, score in zip(CLASSES, all_scores)}            })        except Exception as e:            debug_print(f"Error classifying whole image: {e}")                        # Last resort fallback - just return one detection for the whole image            h, w = img.shape[:2]            debug_print("Using fallback detection for whole image")            results.append({                'box': (0, 0, w, h),                'class': CLASSES[0],  # Default to first class                'confidence': 0.5,                'all_scores': {cls: 0.1 for cls in CLASSES}            })        # Sort results by confidence (highest first)    results.sort(key=lambda x: x['confidence'], reverse=True)        # Limit to max 5 detections to avoid clutter    if len(results) > 5:        results = results[:5]        return resultsdef draw_results(img, results):    """Draw classification results on the image"""    img_copy = img.copy()        colors = {        'Boxes': (0, 255, 0),     # Green        'Metal': (0, 0, 255),     # Blue        'Plastic': (255, 0, 255), # Magenta        'Unknown': (128, 128, 128) # Gray    }        for result in results:        x, y, w, h = result['box']        class_name = result['class']        confidence = result['confidence']                # Ensure box is within image bounds        x = max(0, x)        y = max(0, y)        w = min(w, img_copy.shape[1] - x)        h = min(h, img_copy.shape[0] - y)                # Get color for class (default to gray for unknown)        color = colors.get(class_name, (200, 200, 200))                # Draw rectangle        cv2.rectangle(img_copy, (x, y), (x + w, y + h), color, 4)                # Prepare label text        label = f"{class_name}: {confidence:.2f}"                # Position label above box        label_y = max(y - 10, 20)                # Get text size for background rectangle        text_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)                # Draw background rectangle for text        cv2.rectangle(img_copy, (x, label_y - text_size[1] - 5),                      (x + text_size[0], label_y + 5), color, -1)                # Draw text        cv2.putText(img_copy, label, (x, label_y),                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)        return img_copydef img_to_base64(img):    """Convert image to base64 string for web display"""    _, buffer = cv2.imencode('.png', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))    return base64.b64encode(buffer).decode('utf-8')def test_classification_pipeline():    """Test classification on sample images from each class"""    debug_print("\n===== TESTING CLASSIFICATION PIPELINE =====")        # Check if dataset exists    dataset_dir = './dataset'    if not os.path.exists(dataset_dir):        debug_print(f"Dataset directory not found: {dataset_dir}")        return        # Test with example from each class    for category in CLASSES:        img_path = None        # Try to find images in default or real_world folders        for folder in ['default', 'real_world']:            category_path = os.path.join(dataset_dir, 'classes', category, folder)            if os.path.exists(category_path):                try:                    all_images = [file for file in os.listdir(category_path)                                   if file.lower().endswith(('.png', '.jpg', '.jpeg'))                                   and os.path.isfile(os.path.join(category_path, file))]                    if all_images:                        img_path = os.path.join(category_path, all_images[0])                        break                except Exception as e:                    debug_print(f"Error accessing {category_path}: {e}")                # If no image was found in the dataset structure, try direct class folders        if not img_path:            category_path = os.path.join(dataset_dir, 'classes', category)            if os.path.exists(category_path) and os.path.isdir(category_path):                try:                    all_images = [file for file in os.listdir(category_path)                                   if file.lower().endswith(('.png', '.jpg', '.jpeg'))                                   and os.path.isfile(os.path.join(category_path, file))]                    if all_images:                        img_path = os.path.join(category_path, all_images[0])                except Exception as e:                    debug_print(f"Error accessing {category_path}: {e}")                # If an image was found, test classification        if img_path:            debug_print(f"\nTesting with {category} image: {img_path}")            try:                img = cv2.imread(img_path)                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)                                class_name, confidence, all_scores = extract_and_classify(img, return_all_scores=True)                                debug_print(f"Predicted: {class_name} with confidence {confidence:.4f}")                debug_print("All class scores:")                for cls, score in zip(CLASSES, all_scores):                    debug_print(f"  {cls}: {score:.4f}")                                if class_name != category:                    debug_print(f"INCORRECT CLASSIFICATION! Expected: {category}")                else:                    debug_print(f"Correct classification!")                            except Exception as e:                debug_print(f"Error testing {category} image: {e}")        else:            debug_print(f"No image found for {category}")        debug_print("===== END OF CLASSIFICATION PIPELINE TEST =====\n")# Flask routes@app.route('/')def index():    """Serve the main page"""    return render_template('index.html')@app.route('/upload', methods=['POST'])def upload():    """Handle image upload and classification"""    debug_print("Received upload request")        if 'file' not in request.files:        return jsonify({'error': 'No file part'}), 400        file = request.files['file']        if file.filename == '':        return jsonify({'error': 'No selected file'}), 400        if file and allowed_file(file.filename):        filename = secure_filename(file.filename)        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')        filename = f"{timestamp}_{filename}"        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)        file.save(filepath)                debug_print(f"Saved file to {filepath}")                try:            # Process the image            img = preprocess_image(filepath)            debug_print(f"Loaded image with shape {img.shape}")                        # Detect candidate regions            boxes = object_detection(img)            debug_print(f"Detected {len(boxes)} candidate regions")                        # Classify regions            results = classify_regions(img, boxes)            debug_print(f"Classified {len(results)} objects")                        # Draw results on image            result_img = draw_results(img, results)                        # Convert to base64 for web display            img_base64 = img_to_base64(result_img)                        # Prepare detection data for frontend            detection_data = []            for result in results:                detection_data.append({                    'class': result['class'],                    'confidence': round(result['confidence'] * 100, 1),                    'box': result['box'],                    'all_scores': result.get('all_scores', {})                })                        debug_print("Successfully processed image")            return jsonify({                'success': True,                'img_data': img_base64,                'detections': detection_data            })                    except Exception as e:            import traceback            traceback_str = traceback.format_exc()            debug_print(f"Error processing image: {e}")            debug_print(traceback_str)            return jsonify({'error': f'Error processing image: {str(e)}'}), 500        return jsonify({'error': 'Invalid file type'}), 400@app.route('/static/<path:path>')def serve_static(path):    """Serve static files"""    return send_from_directory('static', path)# Create HTML templateos.makedirs('templates', exist_ok=True)with open('templates/index.html', 'w') as f:    f.write(f"""<!DOCTYPE html><html><head>    <title>Waste Classification - 3-Class Model</title>    <style>        body {{            font-family: Arial, sans-serif;            max-width: 900px;            margin: 0 auto;            padding: 20px;            background-color: #f5f5f5;        }}        h1 {{            color: #2c3e50;            text-align: center;        }}        .upload-container {{            background-color: white;            border-radius: 8px;            padding: 20px;            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);            margin-bottom: 20px;        }}        .result-container {{            background-color: white;            border-radius: 8px;            padding: 20px;            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);            display: none;        }}        #result-image {{            max-width: 100%;            max-height: 600px;            display: block;            margin: 0 auto;        }}        .file-input {{            display: flex;            flex-direction: column;            align-items: center;        }}        .button {{            background-color: #3498db;            color: white;            border: none;            padding: 10px 20px;            border-radius: 4px;            cursor: pointer;            font-size: 16px;            margin-top: 10px;        }}        .button:hover {{            background-color: #2980b9;        }}        .loading {{            text-align: center;            display: none;            margin-top: 20px;        }}        .spinner {{            border: 4px solid #f3f3f3;            border-top: 4px solid #3498db;            border-radius: 50%;            width: 30px;            height: 30px;            animation: spin 1s linear infinite;            margin: 0 auto;        }}        @keyframes spin {{            0% {{ transform: rotate(0deg); }}            100% {{ transform: rotate(360deg); }}        }}        .detection-list {{            list-style-type: none;            padding: 0;        }}        .detection-item {{            padding: 10px;            margin: 5px 0;            border-radius: 4px;            color: white;            font-weight: bold;        }}        .Boxes {{ background-color: #2ecc71; }}        .Metal {{ background-color: #3498db; }}        .Plastic {{ background-color: #9b59b6; }}        .Unknown {{ background-color: #95a5a6; }}        .legend {{            display: flex;            justify-content: center;            flex-wrap: wrap;            margin-top: 20px;        }}        .legend-item {{            display: flex;            align-items: center;            margin: 0 10px;        }}        .legend-color {{            width: 20px;            height: 20px;            margin-right: 5px;            border-radius: 3px;        }}        .user-info {{            text-align: right;            font-size: 0.8em;            color: #7f8c8d;            margin-top: 30px;        }}        .debug-info {{            background-color: #f8f9fa;            border-left: 4px solid #17a2b8;            padding: 10px;            margin-top: 10px;            font-family: monospace;            font-size: 12px;            display: none;        }}        .debug-toggle {{            background-color: #17a2b8;            color: white;            border: none;            padding: 5px 10px;            border-radius: 4px;            cursor: pointer;            font-size: 12px;            margin-top: 5px;        }}        .scores-container {{            display: flex;            flex-wrap: wrap;            margin-top: 5px;        }}        .score-bar {{            height: 8px;            margin-top: 2px;            border-radius: 2px;        }}        .threshold-container {{            margin-top: 15px;            text-align: center;        }}        .threshold-label {{            display: block;            margin-bottom: 5px;            font-weight: bold;        }}        .threshold-value {{            font-weight: bold;            color: #3498db;        }}    </style></head><body>    <h1>Waste Classification - 3-Class Model</h1>    <p style="text-align: center; color: #7f8c8d;">        Current Model: 3 Classes (Boxes, Metal, Plastic)    </p>        <div class="upload-container">        <h2>Upload an Image</h2>        <form id="upload-form" enctype="multipart/form-data">            <div class="file-input">                <input type="file" id="file-input" name="file" accept=".jpg, .jpeg, .png">                <button type="submit" class="button">Classify Waste</button>            </div>        </form>                <div class="threshold-container">            <label class="threshold-label" for="confidence-threshold">                Confidence Threshold: <span id="threshold-value" class="threshold-value">{CONFIDENCE_THRESHOLD * 100}%</span>            </label>            <input type="range" id="confidence-threshold" min="10" max="90" value="{CONFIDENCE_THRESHOLD * 100}"                   style="width: 80%; margin: 0 auto; display: block;">        </div>                <div class="loading" id="loading">            <div class="spinner"></div>            <p>Processing image...</p>        </div>    </div>        <div class="result-container" id="result-container">        <h2>Classification Results</h2>        <div class="legend">            <div class="legend-item">                <div class="legend-color Boxes"></div>                <span>Boxes</span>            </div>            <div class="legend-item">                <div class="legend-color Metal"></div>                <span>Metal</span>            </div>            <div class="legend-item">                <div class="legend-color Plastic"></div>                <span>Plastic</span>            </div>        </div>        <img id="result-image" src="">        <h3>Detected Items:</h3>        <ul class="detection-list" id="detection-list">            <!-- Detections will be added here -->        </ul>    </div>    <div class="user-info">        Last updated: 2025-05-07 06:00:26<br>        User: Zeyad-Diaa-1242    </div>    <script>        document.addEventListener('DOMContentLoaded', function() {{            // Handle confidence threshold changes            const thresholdSlider = document.getElementById('confidence-threshold');            const thresholdValue = document.getElementById('threshold-value');                        thresholdSlider.addEventListener('input', function() {{                thresholdValue.textContent = this.value + '%';            }});                        // Handle form submission            const form = document.getElementById('upload-form');            form.addEventListener('submit', function(e) {{                e.preventDefault();                                const fileInput = document.getElementById('file-input');                const file = fileInput.files[0];                                if (!file) {{                    alert('Please select an image file');                    return;                }}                                // Show loading spinner                document.getElementById('loading').style.display = 'block';                                // Create FormData and send request                const formData = new FormData();                formData.append('file', file);                formData.append('threshold', thresholdSlider.value / 100);                                fetch('/upload', {{                    method: 'POST',                    body: formData                }})                .then(response => response.json())                .then(data => {{                    // Hide loading spinner                    document.getElementById('loading').style.display = 'none';                                        if (data.success) {{                        // Show results container                        document.getElementById('result-container').style.display = 'block';                                                // Set result image                        document.getElementById('result-image').src = 'data:image/png;base64,' + data.img_data;                                                // Add detections to list                        const detectionList = document.getElementById('detection-list');                        detectionList.innerHTML = '';                                                if (data.detections.length === 0) {{                            detectionList.innerHTML = '<li>No waste items detected</li>';                        }} else {{                            data.detections.forEach((detection, index) => {{                                const listItem = document.createElement('li');                                listItem.className = `detection-item ${{detection.class}}`;                                listItem.textContent = `${{detection.class}}: ${{detection.confidence}}% confidence`;                                                                // Create debug toggle button                                const debugButton = document.createElement('button');                                debugButton.textContent = "Show details";                                debugButton.className = "debug-toggle";                                debugButton.onclick = function() {{                                    const debugInfo = document.getElementById(`debug-${{index}}`);                                    if (debugInfo.style.display === 'none') {{                                        debugInfo.style.display = 'block';                                        this.textContent = "Hide details";                                    }} else {{                                        debugInfo.style.display = 'none';                                        this.textContent = "Show details";                                    }}                                }};                                                                // Create debug info div                                const debugInfo = document.createElement('div');                                debugInfo.id = `debug-${{index}}`;                                debugInfo.className = "debug-info";                                debugInfo.style.display = 'none';                                                                // Add score bars                                const scoresContainer = document.createElement('div');                                scoresContainer.className = "scores-container";                                                                if (detection.all_scores) {{                                    const allScores = detection.all_scores;                                    const classNames = Object.keys(allScores);                                                                        classNames.forEach(cls => {{                                        const score = allScores[cls];                                        const scoreWrapper = document.createElement('div');                                        scoreWrapper.style.width = "33%";                                        scoreWrapper.style.padding = "5px";                                                                                // Class name and score                                        const scoreText = document.createElement('div');                                        scoreText.textContent = `${{cls}}: ${{(score * 100).toFixed(1)}}%`;                                        scoreText.style.fontSize = "12px";                                                                                // Progress bar                                        const scoreBar = document.createElement('div');                                        scoreBar.className = `score-bar ${{cls}}`;                                        scoreBar.style.width = `${{score * 100}}%`;                                                                                scoreWrapper.appendChild(scoreText);                                        scoreWrapper.appendChild(scoreBar);                                        scoresContainer.appendChild(scoreWrapper);                                    }});                                }}                                                                debugInfo.appendChild(scoresContainer);                                                                // Add box coordinates                                const boxInfo = document.createElement('p');                                boxInfo.textContent = `Box: x=${{detection.box[0]}}, y=${{detection.box[1]}}, w=${{detection.box[2]}}, h=${{detection.box[3]}}`;                                debugInfo.appendChild(boxInfo);                                                                listItem.appendChild(debugButton);                                listItem.appendChild(debugInfo);                                detectionList.appendChild(listItem);                            }});                        }}                                                // Scroll to results                        document.getElementById('result-container').scrollIntoView({{                            behavior: 'smooth'                        }});                    }} else {{                        alert('Error: ' + data.error);                    }}                }})                .catch(error => {{                    document.getElementById('loading').style.display = 'none';                    alert('Error processing image: ' + error);                }});            }});        }});    </script></body></html>""")def open_browser():    """Open web browser after a short delay"""    time.sleep(1.5)    webbrowser.open('http://127.0.0.1:5000')if __name__ == '__main__':    print("\n=== Waste Classification GUI - Advanced Debugging Version ===")    print(f"Classes: {', '.join(CLASSES)}")    print(f"Using classification model: {MODEL_PATH}")    print(f"Using feature config: {FEATURE_CONFIG_PATH}")    print(f"Using feature scaler: {FEATURE_SCALER_PATH}")    print(f"Using feature extractor model: {FEATURE_MODEL_PATH}")    print("\nRunning test classification pipeline to diagnose issues...")        test_classification_pipeline()        print("\nStarting web interface...")    print("Access the interface at http://127.0.0.1:5000")        threading.Thread(target=open_browser).start()        app.run(debug=False, port=5000)